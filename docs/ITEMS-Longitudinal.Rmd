---
title: "ITEMS: Longitudinal Data Analysis"
author: "Tessa L. Johnson"
date: "`r Sys.Date()`"
output: 
   bookdown::gitbook:
     self_contained: TRUE
     split_by: "section+number"
---

```{r setup, include = FALSE}

##--LIBRARIES--##
#library(ITEMSlme)
devtools::load_all()
library(magrittr)


##--OPTIONS--##
knitr::opts_chunk$set(
  fig.path = here::here("inst/output/Fig_")
)

```

# NLSY Example

In this example, we will be using data from the National Longitudinal Survey of Youth (NLSY). The current subset of data comes from assessments administered to mother-child pairs starting in 1986. Data were restricted to children ages 6-8 with complete data at the first wave of measurement. Data were retained from only one child per mother.

More information about the example data can be found here:

*  [Curran, P. J. (1997). Comparing three modern approaches to longitudinal data analysis: An examination of a single developmental sample. In _Symposium conducted at the meeting of the Society for Research on child Development, Washington, DC._](https://jflournoy.github.io/assets/pdf/srcdmeth.pdf)

# Getting Started

In this worked example, we will follow the guidelines presented in the [ITEMS](https://ncme.elevate.commpartners.com/) Longitudinal Data Analysis module. The basic structure of this guided example is as follows:

*  [Loading and manipulating data][Getting Started]
*  [Performing exploratory data analysis][Exploratory Data Analysis]
*  [Conducting mixed-effects modeling using `nlme::lme`][Model Fitting]
*  [Graphically evaluating modeling assumptions][Model Diagnostics]

Throughout these sections, we present example code for producing display-quality tables and plots for different components of the longitudinal data analysis. While there are several examples in this guide, there are even more ways to examine and present longitudinal data. The documentation for [`ggplot2`](https://ggplot2.tidyverse.org/) and [`gt`](https://gt.rstudio.com/) are great places to go for questions about producing plots and tables, respectively, and the documentation for the [`nlme`](https://cran.r-project.org/web/packages/nlme/nlme.pdf) package is the main resource for questions mixed effects model code. In addition, interested readers will find many helpful examples in Pinhero & Bates (2000):

*  Pinheiro, J., & Bates, D. (2006). _Mixed-effects models in S and S-PLUS._ Springer Science & Business Media.

## Load Data 

To load the data, we use the `readr::read_csv` function. The `na = "-99"` statement tells `readr` how to recode missing data.

During this step, there are a few variables we would like to rename to facilitate pivoting (converting from wide format to long format) later on, so we write a renaming function (`insert_underscore`). The renaming function inserts a "_" character after the initial set of alphabet characters in the original column name but before any non-alphabet characters. The variables we will rename include:

*  ag(1-4) = age at each wave; 
*  an(1-4) = anti-social behavior score at each wave; and 
*  r(1-4) = reading score at each wave.
  
Last, we convert the variable "gen" (child's assigned sex) to a factor variable with the following levels:

*  0 = "female" and
*  1 = "male".

```{r read-data}

##--TUTORIAL DATASETS--##

# read data
path_dat <- system.file(
  "extdata",
  "anti-read.csv",
  package = "ITEMSlme",
  mustWork = TRUE
)

# renaming function
insert_underscore <- function(names){
  sub("^([[:alpha:]]+)", "\\1_", names)
}

# read in the data with readr::read_csv
dat_wide <- path_dat %>%
  readr::read_csv(., na = "-99", col_types = readr::cols()) %>%
  dplyr::rename_with(
    insert_underscore,
    dplyr::starts_with(c("ag", "an", "r"))
  ) %>%
  dplyr::mutate(
    gen = forcats::fct_recode(as.factor(gen), female = "0", male = "1")
  ) %>%
  print(.)

```

## Wide to Long 

Because we have 3 repeated measures variables ("ag", "an" and "r"), we use the "names_pattern" argument of `tidyr::pivot_longer`. "names_pattern" uses a regular expression "(.+)_(.+)" in combo with the "names_to" argument c(".value", "wave") to save all of the data from each repeated measures variable under the names "an", "r", and "ag". The new "wave" variable contains information about when each measurement was taken, drawing its values from the number at the end of the original column name. For example, all of the data from the original column "an_2" will be stored in the new "an" variable with a "wave" code of "2". Because there are 4 waves of measurement, there will now be 4 rows for each person with complete data (n.b., children with missing data will have fewer rows), which you can double check by looking at the "id" column.
  
In the `dplyr::mutate` step, we subtract 1 from each value of "wave" because we want our initial measurement to be coded "0". This will have implications for the interpretation of the intercept when we move to the modeling phase.
  
Finally, we rename all our variables to something more informative. This step isn't strictly necessary, but often it is useful for revisiting and collaborating on code to use informative variable names.

```{r pivot-long}

# pivot wide to long
dat_long <- dat_wide %>%
  tidyr::pivot_longer(
    cols = c(dplyr::contains("_")),
    names_to = c(".value", "wave"),
    names_pattern = c("(.+)_(.+)")
  ) %>%
  dplyr::mutate(., wave = as.numeric(wave) - 1) %>%
  dplyr::rename(
    person_id = id,
    assigned_sex = gen,
    mom_age = momage,
    home_cog = homecog,
    home_emo = homeemo,
    anti_score = an,
    read_score = r,
    child_age = ag
  ) %>%
  print(.)
  
```

# Exploratory Data Analysis 

We choose age here rather than wave because children were all different ages at the first wave of measurement and waves were not completed at the exact same time for each child (meaning that some children were measured every 2 years, while others were measured at wave 1, then 3 years later for wave 2, then 2 years later for wave 3, etc.). Anti-social behavior trajectory may have a developmental component that would get masked if we looked across waves rather than age.

During this section, we showcase both the `dplyr::group_by` and `dplyr::summarize` functions, which help us calculate descriptive statistics for each level of `child_age`. Then, we demonstrate the `gt` package, used for producing display-quality tables of results.

## Missingness 

Like many longitudinal datasets, the data used in this example contain missingness. When using mixed-effects models, it is important to understand where and how missing observations appear. As we learned in [Getting Started], the current data were restricted to children with complete data at the first wave only, though children could appear in the dataset if they were missing data on the second, third, or fourth wave of data collection. To better understand missing data on the outcome, anti-social behavior, we provide examples of four different visualization plots.

### Missing Data Setup

Because we plan to analyze our data by *age* and not *wave*, let's first get a sense of how many anti-social scores are missing at each age level. We know that children were measured up to four times each, but children ranged from ages 6 - 15 in the dataset. Even though we don't have an anti-social behavior score for each child at each age (6, 7, 8, 9, 10...), we know that *theoretically* each child could have contributed an anti-social behavior score at each age.

Using the `pivot` functions from the `tidyr` package, we can identify missing data at each age for each child:

```{r miss-setup}

dat_miss <- dat_long %>%
  dplyr::select(., person_id, child_age, anti_score) %>%
  dplyr::filter(., !is.na(child_age)) %>%
  tidyr::pivot_wider(
    names_from = "child_age",
    values_from = c("anti_score")
  ) %>%
  tidyr::pivot_longer(
    cols = -person_id,
    names_to = "child_age",
    values_to = "anti_score"
  ) %>%
  dplyr::mutate(
    child_age = as.numeric(child_age),
    anti_miss = dplyr::if_else(is.na(anti_score), 1, 0)
  ) %>%
  dplyr::left_join(., dat_long) %>%
  dplyr::select(., person_id, child_age, wave, anti_score, anti_miss) %>%
  dplyr::mutate(., fill_pal = dplyr::case_when(
    !is.na(wave) ~ wave,
    TRUE ~ 4
  )) %>%
  dplyr::arrange(., anti_miss, child_age, person_id) %>%
  print(.)


```

### Lollipop Plot 

If children were measured 4 times over 10 possible ages, we could reasonably expect to be missing anti-social behavior scores at a rate of 60\% in each age group, assuming that missingness were distributed uniformly and that children were all measured at evenly spaced intervals. Let's explore this assumption using what is known as a "lollipop plot". We include a horizontal dashed line to indicate the 60\% threshold.

We can also use this plot to highlight places where missingness is much higher (or lower) than what we expect using colors and labels. In plotting, we find that at age 15, about 98\% of possible anti-social behavior scores are missing, suggesting that most children didn't reach age 15 by the end of the study.

```{r miss-lolli}

# helper for axis limits
age_lim <- c(min(dat_long$child_age, na.rm = TRUE),
             max(dat_long$child_age, na.rm = TRUE))

# adjust dat_miss for lollipop plot
dat_lollipop <- dat_miss %>%
  dplyr::group_by(., child_age) %>%
  dplyr::summarise(
    pct_miss = mean(anti_miss, na.rm = TRUE) * 100
  )

# plot
dat_lollipop %>%
  ggplot2::ggplot(
    ggplot2::aes(x = child_age, y = pct_miss)
  ) +
  ggplot2::geom_segment(
    ggplot2::aes(x = child_age, xend = child_age, y = 0, yend = pct_miss),
    color = dplyr::if_else(
      dat_lollipop$pct_miss > 95, 
      viridis::plasma(n = 4, end = 0.75)[4], 
      "gray25"
    ), 
    size = dplyr::if_else(dat_lollipop$pct_miss > 95, 1.3, 0.7)
  ) +
  ggplot2::geom_point(
    color = dplyr::if_else(
      dat_lollipop$pct_miss > 95, 
      viridis::plasma(n = 4, end = 0.75)[4], 
      "gray25"
    ), 
    size = dplyr::if_else(dat_lollipop$pct_miss > 95, 5, 2)
  ) +
  ggplot2::geom_text(
    ggplot2::aes(
      x = child_age - 0.5,
      y = pct_miss - 5,
      label = paste0(round(pct_miss, 1), "%")
    ),
    data = dat_lollipop %>% dplyr::filter(pct_miss > 95),
    vjust = 1,
    hjust = 0.5
  ) +
  ggplot2::geom_curve(
    ggplot2::aes(
      x = child_age - 0.5, 
      y = pct_miss - 5, 
      xend = child_age, 
      yend = pct_miss),
    data = dat_lollipop %>% dplyr::filter(pct_miss > 95),
    arrow = ggplot2::arrow(length = ggplot2::unit(0.03, "npc")),
    curvature = -0.5
  ) +
  ggplot2::geom_hline(yintercept = 60, color = "gray50", linetype = "dashed") +
  ggplot2::scale_x_continuous(
    limits = c(age_lim[1] - .5, age_lim[2] + .5),
    breaks = seq(age_lim[1], age_lim[2], 1)
  ) +
  ggplot2::theme(
    legend.position = "none"
  ) +
  ggplot2::xlab("Child Age") +
  ggplot2::ylab("Percent Missing") +
  ggplot2::ggtitle("Percent of Children Missing Anti-Social Scores by Age")

```

### Bar Plot by Pattern

Another helpful way to examine missingness in longitudinal data is to look at the *patterns* of missingness. We can think about this like within-person attrition. In other words, for each person, we calculate the percent of measurement waves they participated in out of the possible 4. There are four possible options in our situation (we ignore order to keep the example simple):

1.  anti-social data are present for each of the four waves,
1.  anti-social data are present for 3 of the four waves (we ignore order, but you could differentiate between individuals who have data for Waves 1, 2, and 3 and individuals who have data for Waves 1, 3, and 4),
1.  anti-social data are present for 2 of the four waves (again, we ignore order), and
1.  anti-social data are present for 1 wave only (in our case, due to the way our sample was defined, we know that people with only 1 wave of data contributed to the first wave).

```{r miss-attrit-l}
dat_attrit_l <- dat_miss %>%
  dplyr::group_by(., person_id) %>%
  dplyr::summarise(
    total_waves = sum(1 - anti_miss)
  ) %>%
  dplyr::group_by(., total_waves) %>%
  dplyr::summarise(
    ct_waves = dplyr::n(),
    pct_waves = dplyr::n() / NROW(dat_wide)
  )

dat_attrit_l %>%
  ggplot2::ggplot(.) +
  ggplot2::aes(
    x = forcats::fct_reorder(as.factor(total_waves), dplyr::desc(total_waves)),
    y = pct_waves * 100,
    fill = as.factor(total_waves)
  ) +
  ggplot2::geom_bar(stat = "identity") +
  ggplot2::geom_text(
    ggplot2::aes(
      y = pct_waves * 100 + 5,
      label = round(pct_waves * 100, 1)
    ),
    size = 3.5
  ) +
  ggplot2::scale_x_discrete(
    labels = c("4" = "Exactly 4 Waves (All)",
               "3" = "Exactly 3 Waves (Any)",
               "2" = "Exactly 2 Waves (Any)",
               "1" = "Exactly 1 Wave (1st)")
  ) +
  ggplot2::scale_fill_viridis_d(end = 0.75, option = "C") +
  ggplot2::theme(
    legend.position = "none",
    axis.text.x = ggplot2::element_text(
      angle = 45,
      hjust = 1,
      margin = ggplot2::margin(t = 0, r = 0, b = 10, l = 0)
    ),
    axis.text.y = ggplot2::element_text(
      margin = ggplot2::margin(t = 0, r = 0, b = 0, l = 10)
    )
  ) +
  ggplot2::ylim(0, 100) +
  ggplot2::xlab("Number of Data Collection Waves Completed") +
  ggplot2::ylab("Percent of Children \n per Attrition Category") +
  ggplot2::ggtitle("Attrition Patterns of Anti-Social Behavior Scores (n = 405)")

```

### Bar Plot by Wave

In this next bar plot example, we display across-person attrition. Here, we are merely interested in what percent of our sample (n = 405) contributed anti-social data at each wave.

```{r miss-attrit-c}

dat_attrit_c <- dat_miss %>%
  dplyr::filter(., !is.na(wave)) %>%
  dplyr::group_by(., wave) %>%
  dplyr::summarise(
    total_obs = sum(1 - anti_miss),
    pct_obs = sum(1 - anti_miss) / NROW(dat_wide)
  )

dat_attrit_c %>%
  ggplot2::ggplot(.) +
  ggplot2::aes(
    x = as.factor(wave),
    y = pct_obs * 100,
    fill = as.factor(total_obs)
  ) +
  ggplot2::geom_bar(
    stat = "identity"
  ) +
  ggplot2::geom_text(
    ggplot2::aes(
      y = pct_obs * 100 + 5,
      label = round(pct_obs * 100, 1)
    ),
    position = ggplot2::position_dodge(width = 0.9),
    size = 3.5
  ) +
  ggplot2::scale_x_discrete(
    labels = c("0" = "Wave 1",
               "1" = "Wave 2",
               "2" = "Wave 3",
               "3" = "Wave 4")
  ) +
  ggplot2::scale_fill_viridis_d(end = 0.75, option = "C") +
  ggplot2::theme(
    legend.position = "none",
    axis.text.x = ggplot2::element_text(
      angle = 45,
      hjust = 1,
      margin = ggplot2::margin(t = 0, r = 0, b = 10, l = 0)
    ),
    axis.text.y = ggplot2::element_text(
      margin = ggplot2::margin(t = 0, r = 0, b = 0, l = 10)
    )
  ) +
  ggplot2::xlab("Measurement Wave") +
  ggplot2::ylab("Percent of Children \n Responding within Each Wave") +
  ggplot2::ggtitle(
    expression(
      paste("Anti-Social Behavior Score Reporting Rates ",
            "(", n["Wave 1"], " = 405)")
    )
  )
```

### Raster Plot

This last missingness plot example is called a "raster plot". Whereas the previous plots provided an aggregated glimpse of missing data in our dataset, the raster plot displays the missingness for each individual in our data. Using color to indicate the measurement wave and carefully ordering the data in the plot, we can make sense of a large amount of data all at once.

```{r miss-raster}

dat_miss %>%
  ggplot2::ggplot(.) +
  ggplot2::aes(
    x = child_age,
    y = forcats::fct_inorder(as.factor(person_id)),
    fill = as.factor(fill_pal)
  ) +
  ggplot2::geom_raster(hjust = 0.5, vjust = 0.5) +
  ggplot2::scale_x_continuous(
    limits = c(age_lim[1] - .5, age_lim[2] + .5),
    breaks = seq(age_lim[1], age_lim[2], 1)
  ) +
  ggplot2::scale_fill_manual(
    name = "Wave",
    labels = c("1", "2", "3", "4", "Missing Score"),
    values = c(viridis::viridis(4, option = "C", end = 0.75), "grey90")
  ) +
  ggplot2::theme(
    panel.background = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank(),
    panel.grid.major = ggplot2::element_blank(),
    axis.text.x = ggplot2::element_blank(),
    axis.ticks.x = ggplot2::element_blank(),
    legend.position = "bottom"
  ) +
  ggplot2::labs(
    x = "Child Age",
    y = "Child ID",
    title = "Missing Anti-Social Scores by Age and Wave"
  ) +
  ggplot2::coord_flip()


```

### Updated Dataset

In the step above, we learned that very few children were measured at age 15 (in fact, only 8 children were measured at age 15). For the purposes of this guided example, we will remove those 8 children from the analytic dataset to avoid estimation and convergence issues in modeling later on.

_*NOTE: There are better ways to deal with small sample sizes, but those methods are outside the scope of this module. We do not generally recommend deleting observations!*_

```{r remove-ids}

# find ids for children who are 15 at wave 4
remove_id <- dat_long %>%
  dplyr::filter(., child_age == 15) %>%
  dplyr::select(., person_id) %>%
  unlist(.)
  
# remove ids identified in remove_id
dat_final <- dat_long %>%
  dplyr::filter(., !(person_id %in% remove_id))

# check new sample size
dat_final %>%
  dplyr::distinct(., person_id) %>%
  NROW(.)

```

## Univariate Descriptives

Following our exploration of missing data, we proceed to calculate univariate descriptive statistics. Given what we learned about the distribution of data across age groups in the missing data section, let's move forward using the `dat_final` dataset created in [Updated Dataset].

### Univariate Setup

Using the `dat_final` long dataset, it is fairly straightforward to calculate the means, variances, and number of observations of the anti-social behavior scores within each age. Knowing the means and variances within each age group can help us see whether and how anti-social behavior changes on average over time. In addition, understanding whether the variances are changing over time can help us make modeling decisions later on.

Recall that our new sample size is 397, following the steps in [Updated Data]. Each child was measured up to four times (and we retained a row even when missing their anti-social behavior information), so summing the `n`, or number of observations, should yield 397 * 4 = 1588. Note that 249 observations have a child age listed as `NA`. This number tells us how many anti-social behavior scores were not recorded across all measurement waves and individuals. For more information on how the missing anti-social behavior scores are distributed across individuals, see [Raster Plot].

```{r means-vars-ns}

# calculate descriptive statistics for each level of child's age
moment_tab <- dat_final %>%
  dplyr::group_by(., child_age) %>%
  dplyr::summarize(
    n = dplyr::n(),
    mean = round(mean(anti_score, na.rm = TRUE), 2),
    variance = round(var(anti_score, na.rm = TRUE), 2)) %>%
  dplyr::mutate(., child_age = dplyr::case_when(
    is.na(child_age) ~ "Missing",
    TRUE ~ as.character(child_age)
  )) %>%
  print(.)

```

### Univariate Table

Now that we've calculated our univariate descriptive statistics, we will use the `gt` package to create a display-quality table of results. The `gt` package has a similar ethos to `ggplot2`, where each component of a table can be added on to the previous component. Although the intricacies of both `gt` and `ggplot2` are beyond the scope of this module, we thought it was important to demonstrate ways to create reproducible tables and plots for longitudinal data.

```{r calc-moments}

gt_moments <- moment_tab %>%
  gt::gt(.) %>%
  gt::tab_header(
    data = .,
    title = "Univariate Descriptive Statistics for Anti-Social Behavior Scores",
    subtitle = "Means, variances, & number of observations within each age."
  ) %>%
  gt::tab_spanner(
    data = .,
    label = "Summary of Anti-Social Scores by Age", 
    columns = c("n", "mean", "variance")
  ) %>%
  gt::cols_label(
    child_age = "Child Age",
    n = "Num. Obs.",
    mean = "Mean",
    variance = "Variance"
  ) %>%
  gt::tab_options(., row.striping.include_table_body = FALSE) %>%
  gt::tab_style(
    data = .,
    style = gt::cell_borders(
      sides = c("top", "bottom"),
      color = "#ffffff",
      weight = gt::px(0),
      style = "solid"
    ),
    locations = gt::cells_body(
      columns = dplyr::everything(),
      rows = dplyr::everything())
    ) %>%
  gt::cols_align(., align = "center", columns = TRUE) %>%
  gt::fmt_missing(., columns = c("n", "mean", "variance"))

# print plot
gt_moments

# save plot to file
gt_moments %>%
  gt::gtsave(
    data = .,
    path = here::here("inst/output"),
    filename = "Tab_calc-moments.html"
  )

```

## Bivariate Descriptives

One limitation of long-format data is in calculating bivariate descriptive statistics like correlations and covariances. Tidyverse makes converting from long to wide and back fairly simple. To demonstrate, we take our long-format data and convert back to wide in order to calculate the correlation of anti-social behavior scores measured at different ages. These statistics can help us identify possible error covariance structures for our data, important for modeling later on.

Missing data note: Because children were measured generally every 2-3 years, each child will have "missing" data for their anti-social behavior score at ages when they weren't measured (in addition to non-response and other missing data mechanisms). Due to this structure, we treated missing data in the correlation matrix using pairwise complete observations. Missing data treatments like imputation are out of the scope of this module, but suffice it to say that there is a wealth of literature on missing data in longitudinal studies to help guide you.

### Bivariate Setup

Using the `pivot_wider` function like we did in [Univariate Setup], we can create a wide-format dataset with a column for each unique child age (e.g., 6, 7, 8, 9, ...). Then, calculating the correlation matrix proceeds in a straightforward manner. As with calculating the variances by age in [Univariate Setup], calculating the anti-social score correlations by age can help inform us about various modeling choices later.

```{r cors}

cor_tab <- dat_final %>%
  dplyr::select(., person_id, child_age, anti_score) %>%
  dplyr::filter(., !is.na(child_age)) %>%
  dplyr::arrange(., child_age, person_id) %>%
  tidyr::pivot_wider(
    names_from = "child_age",
    values_from = c("anti_score")) %>%
  dplyr::select(., -person_id) %>%
  corrr::correlate(., diagonal = 1, use = "pairwise", quiet = TRUE) %>%
  dplyr::mutate(., child_age = as.numeric(rowname), .before = rowname) %>%
  dplyr::select(., -rowname) %>%
  purrr::map_df(., ~format(round(.x, 2), nsmall = 2)) %>%
  print(.)

```

### Bivariate Table

With a few small tweaks to the raw correlation matrix produced above, we can now use the `gt` package as [before][Univariate Table] to produce a display-quality correlation table. Note that the "---" symbol blocks off the upper triangle of the correlation matrix to reduce visual redundancy, and "NA" symbols within the lower triangle indicate correlations that could not be calculated due to missing data (for example, the correlation for anti-social behavior at age 6 and age 14 is missing because no children were measured at both age 6 and 14).

```{r calc-corr}
# table results
cor_tab_upper <- cor_tab %>%
  dplyr::select(., -child_age)

cor_tab_upper[upper.tri(cor_tab_upper, diag = FALSE)] <- NA

gt_cor_tab <- cor_tab_upper %>%
  dplyr::mutate(., child_age = 6:14, .before = "6") %>%
  gt::gt(.) %>%
  gt::tab_header(
    data = ., 
    title = "Correlation of Anti-Social Scores Across Age",
    subtitle = "Complete pairwise observations were retained."
  ) %>%
  gt::tab_spanner(
    data = ., 
    label = "Self-Correlated Scores by Age", 
    columns = tidyselect::matches("\\d")
  ) %>%
  gt::cols_label(., child_age = "Child Age") %>%
  gt::fmt_missing(., columns = tidyselect::matches("\\d")) %>%
  gt::tab_options(., row.striping.include_table_body = FALSE) %>%
  gt::tab_style(
    data = ., 
    style = gt::cell_borders(
      sides = c("top", "bottom"),
      color = "#ffffff",
      weight = gt::px(0),
      style = "solid"
    ),
    locations = gt::cells_body(
      columns = dplyr::everything(),
      rows = dplyr::everything()
    )
  ) %>%
  gt::cols_align(., align = "center", columns = TRUE)

# print plot
gt_cor_tab

# save plot to file
gt_cor_tab %>%
  gt::gtsave(
    data = .,
    path = here::here("inst/output"),
    filename = "Tab_calc-corr.html"
  )

```

## Trajectories

In this section, we demonstrate two different ways to visualize longitudinal trajectories, or the changes in anti-social behavior score over time. Trajectory plots are very useful in conducting exploratory data analyses because they help us understand the functional form of the outcome. In other words, we can generally spot linearity and non-linearity in a plot. It is also important to plot both the aggregated and disaggregated change over time because the trajectory of the whole sample may not be the same as the trajectory for each individual.

### Aggregated Plot

First, we plot the aggregated means overlaid on individual plotted points of anti-social behavior by child's age. The plot is broken up into two frames based on child's assigned sex, and a linear curve is fitted to each trajectory.

```{r plot-means}

dat_final %>%
  dplyr::group_by(., child_age, assigned_sex) %>%
  dplyr::mutate(., mean = mean(anti_score, na.rm = TRUE)) %>%
  dplyr::ungroup(.) %>%
  ggplot2::ggplot(.) +
  ggplot2::aes(y = mean, x = child_age, color = assigned_sex) +
  ggplot2::geom_jitter(
    ggplot2::aes(y = anti_score, x = child_age),
    position = ggplot2::position_jitter(0.2), color = "lightgray"
  ) +
  ggplot2::stat_smooth(
    formula = y ~ x, 
    method = "lm", 
    se = FALSE,
    size = 1, 
    linetype = "dashed", 
    color = "black"
  ) +
  ggplot2::geom_point(size = 3) +
  ggplot2::geom_line(size = 1.5) +
  ggplot2::xlab("Child's Age") +
  ggplot2::ylab("Antisocial Behavior Score") +
  ggplot2::ggtitle("Sample Mean Trajectories by Sex") +
  ggplot2::scale_color_viridis_d(name = "Sex", option = "C", end = 0.75) +
  ggplot2::theme(
    axis.text.x = ggplot2::element_text(
      margin = ggplot2::margin(t = 0, r = 0, b = 10, l = 0)
    ),
    axis.title.y = ggplot2::element_text(
      margin = ggplot2::margin(t = 0, r = 10, b = 0, l = 0)
    ),
    legend.position = "none"
  ) +
  ggplot2::facet_wrap(dplyr::vars(assigned_sex))

```

### Individual Plot

Second, we plot the anti-social behavior trajectories of a random sample of 12 children. The plots are color-coded based on the child's assigned sex.

```{r spaghet-indv}

# set seed
set.seed(654)

# randomly select individuals (ids) from dat_final
sample_id <- dat_final %>%
  dplyr::distinct(., person_id) %>%
  dplyr::sample_n(., size = 12) %>%
  unlist(.)

# filter dat_final by sampled ids and save plot
dat_final %>%
  dplyr::filter(., person_id %in% sample_id) %>%
  ggplot2::ggplot(.) +
  ggplot2::aes(
    y = anti_score,
    x = child_age, 
    group = person_id,
    color = assigned_sex
  ) +
  ggplot2::geom_smooth(
    lwd = 0.75, method = "lm", se = FALSE, linetype = "dashed", color = "black"
  ) +
  ggplot2::geom_point(size = 2) +
  ggplot2::geom_line(lwd = 1) +
  ggplot2::xlab("Child's Age") +
  ggplot2::ylab("Antisocial Behavior Score") +
  ggplot2::ggtitle("Individual Trajectories Plot") +
  ggplot2::scale_color_viridis_d(name = "Sex", option = "C", end = 0.75) +
  ggplot2::theme(
    axis.text.x = ggplot2::element_text(
      margin = ggplot2::margin(t = 0, r = 0, b = 10, l = 0)
    ),
    axis.title.y = ggplot2::element_text(
      margin = ggplot2::margin(t = 0, r = 10, b = 0, l = 0)
    ),
    legend.position = "bottom") +
  ggplot2::facet_wrap(dplyr::vars(person_id))

```

# Model Fitting 

In the next section, we demonstrate the model-building process for mixed-effects models, including basic model comparisons. After fitting each of these models, we demonstrate how to summarize the global fit comparisons using the `gt` table package to help us identify our best "semi-unconditional" (that is, without predictors but including the time effects) model.

Once we have selected a semi-unconditional model, we add predictors to the model. In this analysis, we are interested in whether the trajectory of anti-social behavior is significantly impacted by a child's assigned sex after controlling for reading score, mom's age, home emotional stimulation, and home cognitive stimulation, which have been standardized. Last, we demonstrate how to summarize the model parameter estimates using the `gt` table package.

Modeling Tips:

*  Use "na.action = na.exclude" to allow for easier post-model evaluation when dataset contains missing data.
*  Include "control = list(maxIter = 100, returnObject = TRUE)" to facilitate model convergence.
*  Especially with larger sample sizes, use maximum likelihood estimation (method = "ML") rather than restricted maximum likelihood during model building; switch to restricted maximum likelihood for the final model.
*  The first argument of nlme::lme gives the structure of the fixed effects, the "random = " argument gives the structure of the random effects.
*  The "weights = " argument specifies the structure of the level-1 error variances; the "correlation = " argument specifies the structure of the level-1 error covariances.

## Unconditional 

In this set of code, we use the `nlme::lme` function to find the "best" random effects and variance/covariance structure for modeling our anti-social behavior scores over time.

While there is a growing interest in the R community in writing functions to draw statistical modeling packages into the tidyverse (see [Tidymodels](https://www.tidymodels.org/)), wrappers for the older `nlme` package, authored by José Pinheiro and Douglas Bates for the S and S-PLUS languages originally, have received less attention. In other words, the output of these functions is a little hairy. The helper package [`broom.mixed`](https://cran.r-project.org/web/packages/broom.mixed/index.html) is built for "tidying" the output of statistical packages and has some methods built for `lme` objects (that is, the result of the `nlme::lme` function). We will use the `broom.mixed` package along with the `anova` function from the built-in `stats` package to do the heavy lifting of displaying model results and model comparisons.

(Note: `broom.mixed` also has a function for extracting tidy global model fit statistics -- `broom.mixed::glance` -- but it is just as easy to tidy up the results from the `anova` function.)

### Intraclass Correlation

Before we start modeling, a common approach in mixed effects models is to calculate the ICC, or intra-class correlation coefficient. This coefficient falls between 0 and 1 and tells us the proportion of variance in the intercept that exists at level 2 relative to the total variance in the model.

In a longitudinal analysis, the ICC is sometimes a contentious statistic to calculate. Because longitudinal models include some time effect, different viewpoints exist as to whether to include the time effect in the model used to estimate the ICC. We will follow recommendations by Lesa Hoffman (2015) to estimate the ICC based on the model with no predictors and without the time effect.

*  Hoffman, L. (2015). _Longitudinal analysis: Modeling within-person fluctuation and change._ Routledge.

Following this method, the estimated intercept for this model yields the grand mean of all of the children's mean anti-social behavior scores. In other words, if we calculated an average anti-social score for each child across all of their measurements and then averaged those averages, we would be pretty close to the estimated intercept for the `null_icc` model. In that case, the interpretation of the ICC is the amount of variability in the person-average anti-social scores. A large ICC (closer to 1) would tell us that there is substantial variability in the average anti-social score across children; a smaller ICC (closer to 0) would tell us that children are similar in average anti-social behavior score.

```{r calc-icc}

##--MODEL FITTING--##

# unconditional (null) model
null_icc <- dat_final %>%
  nlme::lme(
    anti_score ~ 1, 
    data = .,
    na.action = na.exclude,
    method = "ML",
    random = ~ 1 | person_id,
    control = list(maxIter = 100, returnObject = TRUE)
  )

# calculate the ICC
null_icc %>%
  calc_icc(.)

```

### Unconditional Fits

To select our "best" semi-unconditional model, we proceed as follows:

1.  We start with a fully unconditional, intercept-only model (`null_icc`).
1.  Then, we add a fixed effect for our time variable, child's age (`null_fslp`).
1.  Next, we add a random effect for the slope of the time variable (`null_rslp`).
1.  Retaining the fixed and random effects for time, we then explore heterogeneous error variance structure (`null_hvar`).
1.  Keeping the fixed and random effects for time but removing the heterogeneous error variances, we explore compound symmetric error covariance structure (`null_csym`).

Our model building strategy was largely guided by the information we gained from exploratory data analysis. First, we assumed a linear trajectory for the outcome over time in `null_fslp` based on the plots created in [Trajectories]. Noting the wide variability in slopes and intercepts in the [spaghetti plots][Individual Plot] helped us choose to add a random effect for our time variable to the model in `null_rslp`.

In addition, by calculating the variances and correlations across ages in [Univariate Descriptives] and [Bivariate Descriptives], respectively, we were able to make better decisions about how to model the error variance/covariance structure. Knowing that the variances increased slightly though remained fairly similar across age groups, we decided to try out a heterogeneous error variance structure in `null_hvar` using the `weights = nlme::varIdent()` argument. In addition, the pattern of correlations across ages suggested that a compound symmetric error structure might improve our model fit, which we added to the `null_csym` model using the `correlation = nlme::corCompSymm` argument.

```{r null-mods}

# unconditional model with fixed slope for time var
null_fslp <- dat_final %>%
  nlme::lme(
    anti_score ~ 1 + child_age, 
    data = .,
    na.action = na.exclude,
    method = "ML",
    random = ~ 1 | person_id,
    control = list(maxIter = 100, returnObject = TRUE)
  )

# unconditional model with random slope for time var
null_rslp <- dat_final %>%
  nlme::lme(
    anti_score ~ 1 + child_age, 
    data = .,
    na.action = na.exclude,
    method = "ML",
    random = ~ 1 + child_age | person_id,
    control = list(maxIter = 100, returnObject = TRUE)
  )

# unconditional model with heterogeneous variances
null_hvar <- dat_final %>%
  nlme::lme(
    anti_score ~ 1 + child_age, 
    data = .,
    na.action = na.exclude,
    method = "ML",
    random = ~ 1 + child_age | person_id,
    weights = nlme::varIdent(form = ~ 1 | child_age),
    control = list(maxIter = 100, returnObject = TRUE)
  )

# unconditional model with ar1 error covariance
null_csym <- dat_final %>%
  nlme::lme(
    anti_score ~ 1 + child_age,
    data = .,
    na.action = na.exclude,
    method = "ML",
    random = ~ 1 + child_age | person_id,
    correlation = nlme::corCompSymm(
      value = -.3, form = ~ 1 + child_age | person_id
    ),
    control = list(maxIter = 100, returnObject = TRUE)
  )

# example of the raw results from the nlme::lme package
null_csym %>%
  summary(.)

```

### Global Comparisons Table

Using the `anova` function and `gt` package, we can built a display-quality table of global model fit statistics. As recommended in the ITEMS modules, we use the information criteria to compare non-nested models and models with different random effects structures. The "best" model, and the one we will move forward with when adding covariates in the next section, is the one with the lowest AIC and BIC (in this case, the `null_rslp` model with a random effect for time, homogenous error variances, and independent error covariance structure). All models are estimated with maximum likelihood during the model-building phase. 

```{r fit-null-global}

# comparing models
gt_global_tab <- anova(null_icc, null_fslp, null_rslp, null_hvar, null_csym) %>%
  tibble::as_tibble(.) %>%
  dplyr::mutate(
    Name = dplyr::case_when(
      Model == 1 ~ "Intercept-Only",
      Model == 2 ~ "Time (Fixed)",
      Model == 3 ~ "Time (Fixed and Random)",
      Model == 4 ~ "Heterogeneous Variances",
      Model == 5 ~ "Compound Symmetry"
    ),
    AIC = round(AIC, 2), 
    BIC = round(BIC, 2)
  ) %>%
  dplyr::select(., Model, Name, df, AIC, BIC) %>%
  gt::gt(.) %>%
  gt::tab_header(
    data = .,
    title = "Global Model Comparisons",
    subtitle = "Semi-unconditional models with fixed and random effects for time."
  ) %>%
  gt::tab_spanner(
    data = .,
    label = "Model Fit", 
    columns = c("df", "AIC", "BIC")
  ) %>%
  gt::tab_options(
    data = .,
    row.striping.include_table_body = FALSE
  ) %>%
  gt::tab_style(
    data = ., 
    style = gt::cell_borders(
      sides = c("top", "bottom"),
      color = "#ffffff",
      weight = gt::px(0),
      style = "solid"
    ),
    locations = gt::cells_body(
      columns = dplyr::everything(),
      rows = dplyr::everything()
    )
  ) %>%
  gt::cols_align(
    data = .,
    align = "center", columns = c("Model", "df", "AIC", "BIC")
  ) %>%
  gt::cols_align(., align = "left", columns = "Name")  %>%
  gt::tab_footnote(
    data = ., 
    footnote = paste(
      "Models 4 & 5 retain the fixed and random effects for time;", 
      "Model 4 does not contain compound symmetric covariance structure;",
      "Model 5 does not contain heterogeneous variances."
    ),
    locations = gt::cells_column_labels(columns = dplyr::vars(Name))) %>%
  gt::tab_footnote(
    data = ., 
    footnote = "df = Model degrees of freedom.",
    locations = gt::cells_column_labels(columns = dplyr::vars(df))
  )

# print plot
gt_global_tab

# save plot to file
gt_global_tab %>%
  gt::gtsave(
    data = .,
    path = here::here("inst/output"),
    filename = "Tab_fit-null-global.html"
  )
  

```

## Conditional 

In this section of code, we add our predictor of interest, `assigned_sex`, and a slate of standardized covariates to the baseline "best" model identified in the [step above][Global Comparisons Table]: `null_rslp`. If we wanted to conduct further model comparisons for the covariates (e.g., testing the addition of random slopes for the predictors), we could proceed as we did in the section above. Once we have selected our final model, `cond_reml`, we switch the estimation to restricted maximum likelihood (`method = "REML"`).

### Conditional Fits

Let's add predictors to the linear mixed-effects model with random slope for `child_age`. The effects of `read_score`, `mom_age`, `home_emo`, and `home_cog` have been standardized for the purposes of interpretation.

```{r cond-mods}

# conditional model
cond_full <- dat_final %>%
  nlme::lme(
    anti_score ~ 1 + child_age + assigned_sex +
      scale(read_score) + 
      scale(mom_age) + 
      scale(home_emo) +
      scale(home_cog),
    data = .,
    na.action = na.exclude,
    method = "ML",
    random = ~ 1 + child_age | person_id,
    control = list(maxIter = 100, returnObject = TRUE)
  )

# final model fit with REML
cond_reml <- dat_final %>%
  nlme::lme(
    anti_score ~ 1 + child_age + assigned_sex +
      scale(read_score) +
      scale(mom_age) +
      scale(home_emo) +
      scale(home_cog),
    data = .,
    na.action = na.exclude,
    method = "REML",
    random = ~ 1 + child_age | person_id,
    control = list(maxIter = 100, returnObject = TRUE)
  )

# example of raw output
cond_reml %>%
  summary(.)

```

### Parameter Estimates Table

Now, we create a table of parameter estimates for the final model (`cond_reml`), grouped by fixed and random effects (note that we have opted to remove p-values from our table and instead included lower and upper bounds of the 95\% confidence interval):

```{r fit-cond-results}

# table results
gt_results_tab <- cond_reml %>%
  broom.mixed::tidy(., conf.int = TRUE) %>%
  dplyr::select(
    -tidyselect::any_of(c("effect", "group", "df", "statistic", "p.value"))
  ) %>%
  dplyr::mutate(., dplyr::across(where(is.numeric), ~round(., 2))) %>%
  dplyr::rename(
    Parameter = term,
    Estimate = estimate,
    SE = std.error,
    CI_low = conf.low,
    CI_high = conf.high) %>%
  dplyr::mutate(
    Parameter = dplyr::case_when(
      Parameter == "child_age" ~ "Child Age",
      Parameter == "assigned_sexmale" ~ "Male",
      Parameter == "scale(read_score)" ~ "Reading Score (std.)",
      Parameter == "scale(mom_age)" ~ "Mother's Age (std.)",
      Parameter == "scale(home_emo)" ~ "Home Emotional Stimulation (std.)",
      Parameter == "scale(home_cog)" ~ "Home Cognitive Stimulation (std.)",
      Parameter == "sd_(Intercept)" ~ "Std. Dev. (Intercept)",
      Parameter == "cor_child_age.(Intercept)" ~ "Corr. (Intercept. with Child Age)",
      Parameter == "sd_child_age" ~ "Std. Dev. (Child Age)",
      Parameter == "sd_Observation" ~ "Std. Dev. (Residual)",
      TRUE ~ Parameter
    )
  ) %>%
  gt::gt(.) %>%
  gt::tab_header(
    data = .,
    title = "Model Results",
    subtitle = "Conditional model with homogenous variances and independent error covariance."
  ) %>%
  gt::tab_spanner(
    data = .,
    label = "Model Estimates", 
    columns = c("Estimate", "SE", "CI_low", "CI_high")
  ) %>%
  gt::tab_options(., row.striping.include_table_body = FALSE) %>%
  gt::tab_style(
    data = .,
    style = gt::cell_borders(
      sides = c("top", "bottom"),
      color = "#ffffff",
      weight = gt::px(0),
      style = "solid"
    ),
    locations = gt::cells_body(
      columns = dplyr::everything(),
      rows = dplyr::everything()
    )
  ) %>%
  gt::cols_label(., CI_low = "CI (2.5%)", CI_high = "CI (97.5%)") %>%
  gt::cols_align(
    data = ., 
    align = "center", 
    columns = c("Estimate", "SE", "CI_low", "CI_high")
  ) %>%
  gt::cols_align(., align = "left", columns = "Parameter") %>%
  gt::tab_row_group(., group = "Random Effects", rows = 8:11) %>%
  gt::tab_row_group(., group = "Fixed Effects", rows = 1:7) %>%
  gt::fmt_missing(., columns = 2:5) %>%
  gt::tab_footnote(data = .,
    footnote = paste(
      "(std.) = Covariate has been standardized;",
      "Std. Dev. = Estimated standard deviation of the random effect;",
      "Corr. = Estimated correlation between level-2 random effects."
    ),
    locations = gt::cells_column_labels(columns = dplyr::vars(Parameter))
  )

# print plot
gt_results_tab

# save plot to file
gt_results_tab %>%
  gt::gtsave(
    data = .,
    path = here::here("inst/output"),
    filename = "Tab_fit-cond-results.html"
  )
  

```

# Model Diagnostics 

In this section, we demonstrate a few graphical model diagnostic techniques using the level-1 residuals and fitted values as well as the level-2 random effects from our final conditional model, `cond_reml`.

First, we combine the residuals and random effects estimates with the original dataset. Next, we create "base plots", which include the `ggplot2` elements that we will use in each plot. In this case, we split all of our diagnostic plots by levels of child's assigned sex simply for the purposes of demonstration.

Last, we briefly demonstrate graphical diagnostic plots for the following assumptions:

*  normality of residuals and random effects
*  homoskedasticity (constant variance) of residuals across groups
*  independence of level-1 and level-2 errors (level-2 random effects are not assumed independent from each other)

For more on assumption checking in mixed-effects models, see

*  Pinheiro, J., & Bates, D. (2006). _Mixed-effects models in S and S-PLUS._ Springer Science & Business Media.

(Note: Pinhero and Bates are also the authors of the `nlme` package!)

## Diagnostics Setup

### Merge Data

Using the `nlme::ranef`, `fitted`, and `residuals` functions, we can merge our original dataset (`dat_final`) with the output from our final estimated model, `cond_reml`. Note that we choose to use standardized residuals by requesting `type = "pearson"` from the `residuals` function. Recall that because the `dat_final` dataset contains missing observations for both the outcome (anti-social behavior) and predictors, we used the `na.exclude` option when fitting our models in [Conditional Fits]. If we hadn't done this, then we would get errors when trying to re-merge the residuals back with the original data.

```{r tidy-output}

##--Data Prep--##
mod <- cond_reml

model_eval <- mod %>%
  nlme::ranef(., condVar = TRUE) %>%
  tibble::as_tibble(.) %>%
  dplyr::mutate(
    person_id = dat_final %>% dplyr::distinct(., person_id) %>% unlist(.),
    .before = "(Intercept)"
  ) %>%
  dplyr::rename(., resid_int = `(Intercept)`, resid_age = child_age) %>%
  dplyr::right_join(., dat_final, by = "person_id") %>%
  dplyr::mutate(
    resid_id = residuals(mod, type = "pearson"),
    fitted_id = fitted(mod)
  )


```

### Base Plots

To reduce repetition in plotting in the sections below, we create two baseplots for level-1 residual diagnostics and for level-2 random effects diagnostics. These base setups request that the printed plots will all have panels split and colored by child's assigned sex.

```{r setup-plots}
## plot setup
g_l1 <- model_eval %>%
  ggplot2::ggplot(.) +
  ggplot2::aes(colour = assigned_sex, fill = assigned_sex) +
  ggplot2::scale_color_viridis_d(name = "Sex", option = "C", end = 0.75) +
  ggplot2::scale_fill_viridis_d(name = "Sex", option = "C", end = 0.75) +
  ggplot2::theme(legend.position = "none") +
  ggplot2::facet_wrap(~assigned_sex)
  

g_l2 <- model_eval %>%
  dplyr::distinct(., person_id, .keep_all = TRUE) %>%
  ggplot2::ggplot(.) +
  ggplot2::aes(colour = assigned_sex, fill = assigned_sex) +
  ggplot2::scale_color_viridis_d(name = "Sex", option = "C", end = 0.75) +
  ggplot2::scale_fill_viridis_d(name = "Sex", option = "C", end = 0.75) +
  ggplot2::theme(legend.position = "none") +
  ggplot2::facet_wrap(~assigned_sex)

```

## Normality Plots

In this code, we demonstrate how to plot histograms and qq-plots of our residuals and random effects to assess the normality assumption. In our histograms, we should see symmetric residuals centered around 0. The qq-plot helps us see where deviations from normality occur when the dots fail to align with the solid diagonal line.

```{r check-normal}

## Normality of Residuals

# level-1 residual histogram
g_l1 +
  ggplot2::aes(x = resid_id) +
  ggplot2::geom_histogram() +
  ggplot2::xlab("Standardized Residual Value") +
  ggplot2::ylab("Frequency") +
  ggplot2::ggtitle("Histogram of Standardized Level-1 Residuals")

# level-1 qq plot
g_l1 +
  ggplot2::aes(sample = resid_id, colour = assigned_sex) +
  ggplot2::geom_qq() +
  ggplot2::geom_qq_line() +
  ggplot2::xlab("Theoretical Quantiles") +
  ggplot2::ylab("Sample Quantiles") +
  ggplot2::ggtitle("QQ-Plot of Standardized Level-1 Residuals")

# level-2 random effect histogram (intercept)
g_l2 +
  ggplot2::aes(x = resid_int) +
  ggplot2::geom_histogram() +
  ggplot2::xlab("Random Effect") +
  ggplot2::ylab("Frequency") +
  ggplot2::ggtitle("Histogram of Level-2 Random Effects (Intercept)")

# level-2 qq plot (intercept)
g_l2 +
  ggplot2::aes(sample = resid_int) +
  ggplot2::geom_qq() +
  ggplot2::geom_qq_line() +
  ggplot2::xlab("Theoretical Quantiles") +
  ggplot2::ylab("Sample Quantiles") +
  ggplot2::ggtitle("QQ-Plot of Level-2 Random Effects (Intercept)")

# level-2 random effect histogram (random time slope)
g_l2 +
  ggplot2::aes(x = resid_age) +
  ggplot2::geom_histogram() +
  ggplot2::xlab("Random Effect") +
  ggplot2::ylab("Frequency") +
  ggplot2::ggtitle("Histogram of Level-2 Random Effects (Time)")

# level-2 qq plot (random time slope)
g_l2 +
  ggplot2::aes(sample = resid_age) +
  ggplot2::geom_qq() +
  ggplot2::geom_qq_line() +
  ggplot2::xlab("Theoretical Quantiles") +
  ggplot2::ylab("Sample Quantiles") +
  ggplot2::ggtitle("QQ-Plot of Level-2 Random Effects (Time)")

```

## Homoskedasticity Plots

The assumption of homoskedasticity for multilevel models states that the level-1 residuals should be centered around 0 for each group (in our case, child), and that the variance of each child's scores is the same across children. We can assess this both by plotting the residuals against fitted values, looking for points to be randomly distributed across the plot. Using grouped boxplots, we can also check to see whether each person's box has the same size (because our sample size is large, the "boxes" will appear more like lines).

```{r check-homog}

## Homogeneity of Variance Assumption (Level 1)

# level-1 residual x fitted scatterplot
g_l1 +
  ggplot2::aes(x = fitted_id, y = resid_id) +
  ggplot2::geom_point() +
  ggplot2::geom_hline(yintercept = 0) +
  ggplot2::xlab("Fitted Value") +
  ggplot2::ylab("Standardized Residual") +
  ggplot2::ggtitle("Scatterplot of Fitted Values and Standardized Level-1 Residuals")

# level-1 group boxplot
g_l1 +
  ggplot2::aes(
    x = as.factor(person_id), 
    y = resid_id, 
    group = as.factor(person_id)
  ) +
  ggplot2::geom_boxplot() +
  ggplot2::theme(
    axis.ticks.x = ggplot2::element_blank(),
    axis.text.x = ggplot2::element_blank()
  ) + 
  ggplot2::xlab("Child ID") +
  ggplot2::ylab("Standardized Residual") +
  ggplot2::ggtitle("Grouped Boxplot of Standardized Level-1 Residuals")

```

## Independence Plots

Last, we check the assumption of independence across level-1 and level-2 residuals/random effects. This assumption states that the level-1 residuals should not be related to the level-2 random effects. We assess this using scatter plots.

We also plot the level-2 random effects against one another. As shown in our [model results][Assessing Covariate Effects], the correlation between the level-2 intercept random effect and level-2 time random effect is not statistically different from 0, which we can assess visually using this scatter plot.

```{r check-indep}

## Independence of Residuals Assumption

# level-1 residuals & level-2 random effects (intercept)
g_l1 +
  ggplot2::aes(x = resid_id, y = resid_int) +
  ggplot2::geom_point() +
  ggplot2::xlab("Standardized Residual") +
  ggplot2::ylab("Random Effect (Intercept)") +
  ggplot2::ggtitle("Scatterplot of Standardized Level-1 Residuals and Level-2 Random Effects")

## level-1 residuals & level-2 random effects (random time slope)
g_l1 +
  ggplot2::aes(x = resid_id, y = resid_age) +
  ggplot2::geom_point() +
  ggplot2::xlab("Standardized Residual") +
  ggplot2::ylab("Random Effect (Time)") +
  ggplot2::ggtitle("Scatterplot of Standardized Level-1 Residuals and Level-2 Random Effects")

## level-2 random effects (intercept & random time slope) - not independent
g_l2 +
  ggplot2::aes(x = resid_age, y = resid_int) +
  ggplot2::geom_point() +
  ggplot2::xlab("Random Effect (Time)") +
  ggplot2::ylab("Random Effect (Intercept)") +
  ggplot2::ggtitle("Scatterplot of Level-2 Random Effects")
  

```


